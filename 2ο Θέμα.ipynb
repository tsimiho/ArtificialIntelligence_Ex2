{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RQChnnUNRWa3"
      },
      "source": [
        "## Ομάδα \n",
        "\n",
        "Στοιχεία Μέλους 1: Τσιμιχόδημος Αχιλλέας 03119140\n",
        "\n",
        "Στοιχεία Μέλους 2: Λίτσος Ιωάννης 03119135"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YNwhI6744rUa"
      },
      "source": [
        "# Τεχνητή Νοημοσύνη: Εργαστηριακή Άσκηση 2\n",
        "---\n",
        "\n",
        "Ο στόχος της εργασίας είναι η κατασκευή ενός συστήματος προτάσεων (Recommendation System) για ταινίες. Οι προτάσεις αυτές θα πηγάζουν τόσο από τα χαρακτηριστικά της ταινίας όσο και από ορισμένες αξιολογήσεις του κάθε χρήστη.\n",
        "\n",
        "Στα δεδομένα της άσκησης περιλαμβάνονται ένα αρχείο με το όνομα movies_metadata.csv το όποιο περιέχει τα χαρακτηριστικά κάθε ταινίας όπως θέμα, σκηνοθέτης ηθοποιοί, λέξεις κλειδιά κ.α. από το imdb καθώς και τα αρχεία ratings.csv τα όποια περιέχουν πραγματικές αξιολογήσεις χρηστών, χωρισμένες σε train και σε test.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "021xhsuy4rUa"
      },
      "source": [
        "# Εκφώνηση\n",
        "Στην παρούσα εργασία σας ζητείται να μελετήσετε και να υλοποιήσετε τα παρακάτω:<br>\n",
        "\n",
        "### Μέρος 1\n",
        "Στο μέρος 1 και 2 θα εργαστείτε μόνο με το αρχείο movies_metadata.csv, ενώ στο μέρος τρία θα δουλέψετε και με τα αρχεία των αξιολογήσεων.\n",
        "#### Ερώτημα 1α\n",
        "\n",
        "Αρχικά θα πρέπει, αφού μελετήσετε τη δομή και τα χαρακτηριστικά του movies_metadata.csv, να κατασκευάσετε μια βάση γνώσης για την Prolog η όποια ουσιαστικά θα αποτελεί τον κόσμο με τον όποιο θα εργαστείτε στην συνέχεια. Τα κατηγορήματα που θα δημιουργηθούν θα σας βοηθήσουν και στην κατασκευή του recommender και θα είναι της μορφής:\n",
        "\n",
        "```\n",
        "director(Movie, Director).\n",
        "genre(Movie, Genre).\n",
        "```\n",
        "#### Ερώτημα 1β\n",
        "\n",
        "Αφού δημιουργήσετε τον κόσμο του προβλήματος, στη συνέχεια καλείστε να δημιουργήσετε, σε Prolog, απλούς κανόνες οι οποίοι θα βρίσκουν όλες τις ταινίες με:\n",
        "1.\tΚοινό θέμα (κάποιες λέξεις σχετικά με το genre κοινές)\n",
        "2.\tΑρκετά κοινό θέμα (κάποιες λιγότερες λέξεις σχετικά με το genre κοινές π.χ. 3)\n",
        "3.\tΣχετικά κοινό θέμα (λίγες λέξεις σχετικές με το genre κοινές π.χ. 1)\n",
        "4.\tΚοινός σκηνοθέτης\n",
        "5.\tΑκριβώς ίδια πλοκή (κάποιες λέξεις κλειδιά της πλοκής κοινές)\n",
        "6.\tΣχετικά ίδια πλοκή (κάποιες λιγότερες λέξεις κλειδιά κοινές)\n",
        "7.\tΊδιους τους βασικούς ηθοποιούς (και τους 3)\n",
        "8.\tΑρκετά ίδιους βασικούς ηθοποιούς (ορισμένους βασικούς ηθοποιούς κοινούς π.χ. 2)\n",
        "9.\tΣχετικά ίδιους ηθοποιούς (π.χ. 1 από τους 3)\n",
        "10.\tΊδια γλώσσα\n",
        "11.\tΕίναι έγχρωμες ή ασπρόμαυρες\n",
        "12. Κοινό studio παραγωγής\n",
        "13. Κοινή χώρα παραγωγής \n",
        "14. Ίδια δεκαετία \n",
        "\n",
        "Αξίζει να σημειωθεί ότι στα παραπάνω μπορείτε να προσθέσετε περισσότερα ερωτήματα ή να αλλάξετε την κλιμακωσιμότητα των queries (πέρα από το ίδιο, αρκετά ίδιο, σχετικά ίδιο) που θα κατασκευάσετε(π.χ. μια κλίμακα από 1 στα 5 όπου αυτό είναι δυνατόν), μιας και αυτά στην συνέχεια θα χρησιμοποιηθούν για την λειτουργία του recommender. Έτσι μπορείτε να προσθέσετε queries με τα όποια μπορεί να παράγονται καλύτερες συστάσεις  (το αρχείο movie_metadata.csv περιέχει πολλές πληροφορίες ακόμα για κάθε ταινία όπως έτος κυκλοφορίας, βαθμολογία στο imdb, facebοok_likes κ.α.). Το συγκεκριμένο μέρος εργασίας είναι προπαρασκευαστικό οπότε όσο καλύτερα και πλουσιότερα τα ερωτήματα που θα φτιάξετε σε αυτό το μέρος τόσο καλύτερη θα είναι η απόδοσή των συστημάτων συστάσεων των επόμενων ερωτημάτων.\n",
        "\n",
        "Περισσότερες πληροφορίες για το dataset μπορείτε να διαβάσετε σε αυτό το [Link](https://www.kaggle.com/georgefila/movies-metadata).\n",
        "### Μέρος 2: Recommendation System\n",
        "Στο σημείο αυτό καλείστε με βάση αυτά που κάνατε στο μέρος 1 να κατασκευάσετε queries τα όποια θα σας επιστρέφουν παρόμοιες (σε χαρακτηριστικά) ταινίες. Τα ερωτήματα αυτά θα είναι κλιμακούμενα, δηλαδή θα υπάρχουν ερωτήματα που επιστρέφουν αρκετά κοινές ταινίες αλλά και που επιστρέφουν λιγότερο και λιγότερο κοινές (σε μια κλίμακα π.χ. από 1 σε 5). Για παράδειγμα:\n",
        "\n",
        "```\n",
        "find_simmilar_movies_5(\"Pirates Of The Caribbean\", M).\n",
        "M = \"Pirates Of The Caribbean: On Stranger Tides\"\n",
        "M = \"The Chronicles Of Narnia\"\n",
        "M = \"Prince Of Persia: The Sands Of Time\"\n",
        "...\n",
        "```\n",
        "Για παράδειγμα, το παραπάνω ερώτημα θα επιστρέφει αρκετά κοινές σε περιεχόμενο ταινίες με την ταινια \"Pirates Of The Caribbean\". Θα υπάρχουν και αντίστοιχα ερωτήματα που θα βρίσκουν λιγότερο όμοιες ταινίες. Ο δείκτης ομοιότητας των ταινιών είναι αυθαίρετος και μπορείτε να τον ορίσετε εσείς όπως θέλετε, αρκεί να υπάρχει κάποια λογική σύνδεση με τα δεδομένα που περιέχονται στο αρχείο movies_metadata.csv. \n",
        "\n",
        "Συνεπώς η συνάρτηση που θα κάνει τις προτάσεις (recommendation) με είσοδο μια ταινία πρέπει να επιστρέφει-εκτυπώνει μια λίστα με τις προτεινόμενες ταινίες κατά φθίνουσα σειρά ομοιότητας. \n",
        "\n",
        "\n",
        "###3ο Μέρος: Recommendation System Με βάση τις προτιμήσεις - Αξιολογήσεις του χρήστη\n",
        "\n",
        "\n",
        "Σε αυτό το σημείο θα εργαστείτε με τα αρχεία ratings τα όποια περιέχουν αξιολογήσεις (από 1 μέχρι 5) για τις παραπάνω ταινίες. Το προηγούμενο σύστημα συστάσεων προτείνει στον χρήστη ταινίες αποκλειστικά με βάση την ομοιότητά τους. Σε αυτό το σημείο θα γίνει μια αναβάθμιση του συστήματος έτσι ώστε να παράγονται καλύτερες  συστάσεις οι όποιες θα λαμβάνουν υπόψιν και τις προτιμήσεις του χρήστη, οι όποιες θα εξάγονται από τις αξιολογήσεις που έχει κάνει μέχρι στιγμής. \n",
        "\n",
        "Η εκπαίδευση του recommender θα γίνεται ως εξής:\n",
        "\n",
        "Για κάθε ταινία θα υπάρχει ένα score το όποιο αρχικά θε είναι ίσο με 0 και θα διαμορφώνεται από τις αξιολογήσεις κάθε user. Έτσι για έναν χρήστη με βάση τις αξιολογήσεις που υπάρχουν στο αρχείο train_ratings θα πρέπει:\n",
        "\n",
        "1.\tΓια κάθε ταινία που έχει βαθμολογήσει να βρίσκονται οι κοινές ταινίες ανά κλίμακα και στο μέχρι τώρα σκορ κάθε παρόμοιας ταινίας θα προστίθεται ένα βάρος το όποιο θα μπορούσε να είναι το ποσοστό ομοιότητας της ταινίας (δηλαδή ένα βάρος για κάθε κλίμακα, αν δύο ταινίες μοιάζουν ενισχύουμε το βάρος που προσθέτουμε από το να μοιάζουν λιγότερο) επί τον βαθμό που έχει βάλει ο χρήστης για την αρχική ταινία (διαφορετικό είναι ο χρήστης να έχει βάλει 5/5 ή 1/5 σε μια ταινία από 3/5). \n",
        "\n",
        "2. Στη συνέχεια, ανάλογα με το σκορ που έχει σχηματιστεί για κάθε ταινία, θα επιλέγεται αν αυτή θα μπορούσε να είναι προτεινόμενη για τον χρήστη ή όχι και θα μετράμε το πόσο καλά τα πήγε το σύστήμά μας με βάση ορισμένες μετρικές.\n",
        "\n",
        "Η λογική πίσω από την παραπάνω διαδικασία είναι ότι παρόμοιες ταινίες θα έχουν ανάλογο βαθμό. Για παράδειγμα αν ένας χρήστης έχει αξιολογήσει αρκετές  ταινίες οι όποιες είναι sci-fiction με 5/5 τότε μια ταίνια sci-fiction την όποια δεν έχει δεί λογικά θα του αρέσει και θα έπρεπε να την προτείνουμε.\n",
        "\n",
        "Μετά την εκπαίδευση του συστήματος σας καλείστε να δοκιμάσετε τον recommender που κατασκευάσατε στην πράξη. Για τον σκοπό αυτό θα φορτώσετε το αρχείο test_ratings.csv όπου περιέχονται οι αξιολογήσεις του ίδιου χρήστη για άλλες ταινίες. Το σύστημά σας πρέπει να προβλέπει αν μια ταινία θα πρέπει να προταθεί στον χρήστη. Μια ταίνια θεωρούμε οτι προτείνεται στον  χρήστη, αν έχει βαθμό μεγαλύτερο του 3 στο test_ratings. Συνεπώς για την επίβλεψη του συστήματός σας θα πρέπει για κάθε μια από τις ταινίες του αρχείου test_ratings.csv να προβλέψετε εάν θα αρέσει στο χρήστη ή όχι ώστε να την προτείνετε. \n",
        "\n",
        "ΠΡΟΣΟΧΗ! Η \"βαθμολογία\" που θα υπολογίσετε για κάθε ταινία κατά το training δεν είναι απαραίτητα πρόβλεψη της βαθμολογίας που θα έβαζε ο χρήστης. \n",
        "\n",
        "Στην συνέχεια, σε συνδιασμό με τις πραγματικές απαντήσεις του χρήστη θα αξιολογήσετε το σύστημά σας χρησιμοποιόντας τις μετρικές: precision, recall, f1 οι οποίες είναι οι πλέον γνωστές μετρικές και ευρέως χρησιμοποιούμενες τεχνικές για την επίβλεψη-μέτρηση απόδοσης ανάλογων συστημάτων.\n",
        "\n",
        "1. Precision: Δείχνει πόσο ακριβές είναι το σύστημα. Υπολογίζει πόσα από τα στιγμιότυπα τα όποια προβλέψαμε ότι ανήκουν σε μια κλάση όντως ανήκουν σε αυτή. Η μετρική αυτή μας δίνει μια εικόνα σχετικά με τον αριθμό των ταινίων που προβλέψαμε ως προτεινόμενες ενώ δεν θα έπρεπε.\n",
        "\n",
        "2. Recall: Υπολογίζει πόσα από τα στιγμιότυπα που ανήκουν σε μια κλάση (π.χ. προτεινόμενες ταινίες) προβλέφθηκαν σωστά.\n",
        "\n",
        "3. F1: Είναι ένας μέσος μεταξύ των παραπάνω δυο μετρικών, έτσι ώστε να διατηρείται μια ισορροπία μεταξύ τους. Υπολογίζεται από την παρακάτω σχέση:\n",
        "\n",
        "$$F_1=2\\frac{Precision\\times{Recall}}{Precision+Recall}$$\n",
        "\n",
        "Οι παραπάνω συναρτήσεις παρέχονται από την βιβλιοθήκη scikit-learn.\n",
        "\n",
        "Τέλος για την καλύτερη επίβλεψη του συστήματος σας μπορείτε να εκπαιδεύσετε  τον recommender σας με ένα υποσύνολο ταινίων από ελάχιστες, λίγες μέχρι και πολλές (π.χ. 3, 5, 10, 50, ...) για να μελετήσετε κατά πόσο σας βοηθούν οι επιπλέον αξιολογήσεις κάθε φορά (δηλαδή κατά πόσο βελτιώνονται οι παραπάνω μετρικές στο test set). \n",
        "\n",
        "Έτσι π.χ. μπορείτε να εντοπίσετε περιπτώσεις όπως για παράδειγμα ότι με έναν recommender μπορεί να μην επιτυγχάνετε πολύ υψηλό σκορ όσο με άλλους, αλλά το βέλτιστο σκόρ σας επιτυγχάνεται πολύ γρηγόρα π.χ. με μόνο 10 ταινίες αντί 100. Έτσι για παράδειγμα αν ο αλγόριθμος τα πηγαίνει πολύ καλά για τρεις ταινίες και στη συνέχεια το σκορ βελτιώνεται ελάχιστα τότε αυτός ενδείκνυται για ένα σύστημα συστάσεων για νέους χρήστες όπου δεδομένου λίγων ταινιών ο αλγόριθμος είναι σε θέση να το να προτείνει καλές συστάσεις. Ενώ αν η καλύτερη απόδοση του αλγορίθμου σας είναι βέλτιστη με περισσότερες ταινίες π.χ. 50 τότε αυτός ο αλγόριθμος συστάσεων ενδείκνυται για παλιούς χρήστες με πολλές αξιολόγησεις. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9HWH0oMY4rUb"
      },
      "source": [
        "---\n",
        "## Κατασκευή Περιβάλλοντος Εργασίας\n",
        "---\n",
        "### Διάβασμα Αρχείων στο Colab (Μόνο για το Colab)\n",
        "Αν η υλοποίηση γίνει στο google colab τότε μπορεί να χρησιμοποιηθεί το google drive ως file system. Για να γίνει Mount το google drive τρέχουμε τον παρακάτω κώδικα και κλικάρουμε στο link που θα μας εμφανιστεί. \n",
        "\n",
        "```\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.listdir('/gdrive/My Drive')\n",
        "```\n",
        "Έπειτα στην σελίδα που άνοιξε επιλέγουμε το mail μας και στο επόμενο παράθυρο που θα μας ανοίξει πατάμε Να επιτρέπεται. Στην συνέχεια αντιγράφουμε τον κωδικό που θα μας βγάλει και τον κάνουμε paste στο Input που έχει ανοίξει στο colab. Έτσι πλέον αν έχουμε ανεβάσει ένα αρχείο στο google drive μπορούμε να το βρούμε στην θέση:\n",
        "\n",
        "```\n",
        "movies_filename = '/gdrive/My Drive/' + movies_metadata.csv\n",
        "```\n",
        "Μπορούμε πλέον κανονικά να δουλέψουμε φτιάχνοντας φακέλους ή αρχεία και γενικότερα κάνοντας οτιδήποτε θα κάναμε αν ήμασταν τοπικά. \n",
        "\n",
        "### Prolog μέσω Python\n",
        "\n",
        "Το πακέτο που θα χρησιμοποιηθεί για την επικοινωνία Python και Prolog είναι το pyswip (https://pypi.org/project/pyswip/). Για να δουλέψει το Pyswip  χρειάζεται να υπάρχει το Swi-Prolog το όποιο αν δουλεύουμε τοπικά πρέπει να το εγκαταστήσουμε, ακολουθώντας αντίστοιχες οδηγίες στην σελίδα του εργαλείου. Για να γίνει του Swi-Prolog η εγκατάσταση στο Google Colab πρέπει να τρέξουμε τον παρακάτω κώδικα:\n",
        "\n",
        "```\n",
        "!sudo apt-get install software-properties-common\n",
        "!sudo apt-add-repository ppa:swi-prolog/stable\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install swi-prolog\n",
        "```\n",
        "Σε κάποιο σημείο της εκτέλεσης εμφανίζεται ένα μήνυμα ότι πρέπει να πατήσουμε enter σε ένα input για να συνεχίσει η διαδικασία. Έπειτα από αυτό η εκτέλεση θα συνεχίσει χωρίς κάποιο πρόβλημα.\n",
        "\n",
        "Τέλος πρέπει να εγκαταστήσουμε το pyswip (**όπου και να δουλεύουμε**) όπως παρακάτω:\n",
        "\n",
        "```\n",
        "!pip isntall pyswip\n",
        "```\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "doHQmp994rUb"
      },
      "source": [
        "---\n",
        "#Κώδικας για κατασκευή περιβάλλοντος εργασίας\n",
        "\n",
        "##Μόνο για Google Colab\n",
        "\n",
        "Κώδικας για να γίνει Mount to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QOs_gnx4rUb",
        "outputId": "2f5514fa-1142-4ab6-bbe5-9a611201db4e"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# import os\n",
        "# path=\"/content/drive/My Drive/ArtificialIntelligence_Ex2\" # με ευκόλο τρόπο μπορείτε να αλλάξετε το path που είναι αποθηκευμένα τα αρχεία σας"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xZdXjQr64rUc"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# #install swi-prolog\n",
        "# !sudo apt-get install software-properties-common\n",
        "# !sudo apt-add-repository ppa:swi-prolog\n",
        "# !sudo apt-get update\n",
        "# !sudo apt-get install swi-prolog\n",
        "# #install pyswip\n",
        "# #%pip install pyswip\n",
        "# %pip install git+https://github.com/yuce/pyswip@master#egg=pyswip\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GxLahZ-i4rUc"
      },
      "source": [
        "\n",
        "# **Μέρος 1: Μελέτη των Metadata, Δημιουργία κόσμου και των βασικών queries.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "gA3CRz5c4rUc",
        "outputId": "6e065d02-4178-4e53-e38b-1f62d4fd6131"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pyswip import Prolog\n",
        "import ast\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "id": "jnVDBIDw4rUd",
        "outputId": "9173a319-7f54-40f0-cb0d-101102106fe0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>budget</th>\n",
              "      <th>genres</th>\n",
              "      <th>homepage</th>\n",
              "      <th>id</th>\n",
              "      <th>plot_keywords</th>\n",
              "      <th>language</th>\n",
              "      <th>original_title</th>\n",
              "      <th>overview</th>\n",
              "      <th>popularity</th>\n",
              "      <th>...</th>\n",
              "      <th>tagline</th>\n",
              "      <th>movie_title</th>\n",
              "      <th>vote_average</th>\n",
              "      <th>num_voted_users</th>\n",
              "      <th>title_year</th>\n",
              "      <th>country</th>\n",
              "      <th>director_name</th>\n",
              "      <th>actor_1_name</th>\n",
              "      <th>actor_2_name</th>\n",
              "      <th>actor_3_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>237000000</td>\n",
              "      <td>Action|Adventure|Fantasy|Science Fiction</td>\n",
              "      <td>http://www.avatarmovie.com/</td>\n",
              "      <td>19995</td>\n",
              "      <td>culture clash|future|space war|space colony|so...</td>\n",
              "      <td>English</td>\n",
              "      <td>Avatar</td>\n",
              "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
              "      <td>150.437577</td>\n",
              "      <td>...</td>\n",
              "      <td>Enter the World of Pandora.</td>\n",
              "      <td>Avatar</td>\n",
              "      <td>7.2</td>\n",
              "      <td>11800</td>\n",
              "      <td>2009.0</td>\n",
              "      <td>United States of America</td>\n",
              "      <td>James Cameron</td>\n",
              "      <td>Zoe Saldana</td>\n",
              "      <td>Sigourney Weaver</td>\n",
              "      <td>Stephen Lang</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>300000000</td>\n",
              "      <td>Adventure|Fantasy|Action</td>\n",
              "      <td>http://disney.go.com/disneypictures/pirates/</td>\n",
              "      <td>285</td>\n",
              "      <td>ocean|drug abuse|exotic island|east india trad...</td>\n",
              "      <td>English</td>\n",
              "      <td>Pirates of the Caribbean: At World's End</td>\n",
              "      <td>Captain Barbossa, long believed to be dead, ha...</td>\n",
              "      <td>139.082615</td>\n",
              "      <td>...</td>\n",
              "      <td>At the end of the world, the adventure begins.</td>\n",
              "      <td>Pirates of the Caribbean: At World's End</td>\n",
              "      <td>6.9</td>\n",
              "      <td>4500</td>\n",
              "      <td>2007.0</td>\n",
              "      <td>United States of America</td>\n",
              "      <td>Gore Verbinski</td>\n",
              "      <td>Orlando Bloom</td>\n",
              "      <td>Keira Knightley</td>\n",
              "      <td>Stellan Skarsgård</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>245000000</td>\n",
              "      <td>Action|Adventure|Crime</td>\n",
              "      <td>http://www.sonypictures.com/movies/spectre/</td>\n",
              "      <td>206647</td>\n",
              "      <td>spy|based on novel|secret agent|sequel|mi6|bri...</td>\n",
              "      <td>Français</td>\n",
              "      <td>Spectre</td>\n",
              "      <td>A cryptic message from Bond’s past sends him o...</td>\n",
              "      <td>107.376788</td>\n",
              "      <td>...</td>\n",
              "      <td>A Plan No One Escapes</td>\n",
              "      <td>Spectre</td>\n",
              "      <td>6.3</td>\n",
              "      <td>4466</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>Sam Mendes</td>\n",
              "      <td>Christoph Waltz</td>\n",
              "      <td>Léa Seydoux</td>\n",
              "      <td>Ralph Fiennes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>250000000</td>\n",
              "      <td>Action|Crime|Drama|Thriller</td>\n",
              "      <td>http://www.thedarkknightrises.com/</td>\n",
              "      <td>49026</td>\n",
              "      <td>dc comics|crime fighter|terrorist|secret ident...</td>\n",
              "      <td>English</td>\n",
              "      <td>The Dark Knight Rises</td>\n",
              "      <td>Following the death of District Attorney Harve...</td>\n",
              "      <td>112.312950</td>\n",
              "      <td>...</td>\n",
              "      <td>The Legend Ends</td>\n",
              "      <td>The Dark Knight Rises</td>\n",
              "      <td>7.6</td>\n",
              "      <td>9106</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>United States of America</td>\n",
              "      <td>Christopher Nolan</td>\n",
              "      <td>Michael Caine</td>\n",
              "      <td>Gary Oldman</td>\n",
              "      <td>Anne Hathaway</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>260000000</td>\n",
              "      <td>Action|Adventure|Science Fiction</td>\n",
              "      <td>http://movies.disney.com/john-carter</td>\n",
              "      <td>49529</td>\n",
              "      <td>based on novel|mars|medallion|space travel|pri...</td>\n",
              "      <td>English</td>\n",
              "      <td>John Carter</td>\n",
              "      <td>John Carter is a war-weary, former military ca...</td>\n",
              "      <td>43.926995</td>\n",
              "      <td>...</td>\n",
              "      <td>Lost in our world, found in another.</td>\n",
              "      <td>John Carter</td>\n",
              "      <td>6.1</td>\n",
              "      <td>2124</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>United States of America</td>\n",
              "      <td>Andrew Stanton</td>\n",
              "      <td>Lynn Collins</td>\n",
              "      <td>Samantha Morton</td>\n",
              "      <td>Willem Dafoe</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0     budget                                    genres  \\\n",
              "0           0  237000000  Action|Adventure|Fantasy|Science Fiction   \n",
              "1           1  300000000                  Adventure|Fantasy|Action   \n",
              "2           2  245000000                    Action|Adventure|Crime   \n",
              "3           3  250000000               Action|Crime|Drama|Thriller   \n",
              "4           4  260000000          Action|Adventure|Science Fiction   \n",
              "\n",
              "                                       homepage      id  \\\n",
              "0                   http://www.avatarmovie.com/   19995   \n",
              "1  http://disney.go.com/disneypictures/pirates/     285   \n",
              "2   http://www.sonypictures.com/movies/spectre/  206647   \n",
              "3            http://www.thedarkknightrises.com/   49026   \n",
              "4          http://movies.disney.com/john-carter   49529   \n",
              "\n",
              "                                       plot_keywords  language  \\\n",
              "0  culture clash|future|space war|space colony|so...   English   \n",
              "1  ocean|drug abuse|exotic island|east india trad...   English   \n",
              "2  spy|based on novel|secret agent|sequel|mi6|bri...  Français   \n",
              "3  dc comics|crime fighter|terrorist|secret ident...   English   \n",
              "4  based on novel|mars|medallion|space travel|pri...   English   \n",
              "\n",
              "                             original_title  \\\n",
              "0                                    Avatar   \n",
              "1  Pirates of the Caribbean: At World's End   \n",
              "2                                   Spectre   \n",
              "3                     The Dark Knight Rises   \n",
              "4                               John Carter   \n",
              "\n",
              "                                            overview  popularity  ...  \\\n",
              "0  In the 22nd century, a paraplegic Marine is di...  150.437577  ...   \n",
              "1  Captain Barbossa, long believed to be dead, ha...  139.082615  ...   \n",
              "2  A cryptic message from Bond’s past sends him o...  107.376788  ...   \n",
              "3  Following the death of District Attorney Harve...  112.312950  ...   \n",
              "4  John Carter is a war-weary, former military ca...   43.926995  ...   \n",
              "\n",
              "                                          tagline  \\\n",
              "0                     Enter the World of Pandora.   \n",
              "1  At the end of the world, the adventure begins.   \n",
              "2                           A Plan No One Escapes   \n",
              "3                                 The Legend Ends   \n",
              "4            Lost in our world, found in another.   \n",
              "\n",
              "                                movie_title vote_average  num_voted_users  \\\n",
              "0                                    Avatar          7.2            11800   \n",
              "1  Pirates of the Caribbean: At World's End          6.9             4500   \n",
              "2                                   Spectre          6.3             4466   \n",
              "3                     The Dark Knight Rises          7.6             9106   \n",
              "4                               John Carter          6.1             2124   \n",
              "\n",
              "  title_year                   country      director_name     actor_1_name  \\\n",
              "0     2009.0  United States of America      James Cameron      Zoe Saldana   \n",
              "1     2007.0  United States of America     Gore Verbinski    Orlando Bloom   \n",
              "2     2015.0            United Kingdom         Sam Mendes  Christoph Waltz   \n",
              "3     2012.0  United States of America  Christopher Nolan    Michael Caine   \n",
              "4     2012.0  United States of America     Andrew Stanton     Lynn Collins   \n",
              "\n",
              "       actor_2_name       actor_3_name  \n",
              "0  Sigourney Weaver       Stephen Lang  \n",
              "1   Keira Knightley  Stellan Skarsgård  \n",
              "2       Léa Seydoux      Ralph Fiennes  \n",
              "3       Gary Oldman      Anne Hathaway  \n",
              "4   Samantha Morton       Willem Dafoe  \n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Η βιβλιοθήκη pandas είναι χρήσιμη για την εργασία με τέτοια δεδομένα\n",
        "import pandas as pd \n",
        "# path = '/content/drive/MyDrive/ArtificialIntelligence_Ex2/'\n",
        "path = './'\n",
        "# Διάβασμα του αρχείου 'movie_metadata.csv' \n",
        "data = pd.read_csv(path + \"movies_metadata.csv\") \n",
        "#Στο csv υπαρχούν κελία με nan τιμές\n",
        "#Στις θέσεις αυτές βάζουμε 'UNK' πράγμα που  κάνουμε με την παρακάτω συνάρτηση\n",
        "data.fillna(\"UNK\", inplace=True)\n",
        "# Preview the first 5 lines of the loaded data \n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sPAqSe0n4rUd"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "  text = text.replace(u'\\xa0', u'')\n",
        "  text = text.replace(u\"'\", u'')\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RcOo0hyJ4rUd"
      },
      "outputs": [],
      "source": [
        "#create World\n",
        "#Ορίζουμε τον κόσμο μας\n",
        "prolog = Prolog()\n",
        "\n",
        "#Για κάθε row του πίνακα φτιάχνουμε τα κατηγορήματα που θέλουμε να αποθηκέυσουμε\n",
        "#αρχικά σε μια λίστα με το όνομα literals\n",
        "literals = []\n",
        "movie_score = {}\n",
        "for row in data.itertuples(index=True, name='Pandas'):\n",
        "  movie_title = clean_text(getattr(row, 'movie_title'))\n",
        "  literals.append(\"movie_title('\"+ movie_title +\"')\")\n",
        "\n",
        "  for genre in getattr(row, 'genres').split(\"|\"):\n",
        "    literals.append(\"genre('\"+ movie_title +\"','\"+ genre +\"')\")\n",
        "\n",
        "  budget = getattr(row,\"budget\")\n",
        "  literals.append(\"budget('\"+ movie_title +\"','\"+ str(budget) +\"')\")\n",
        "\n",
        "  home_page = clean_text(getattr(row,\"homepage\"))\n",
        "  literals.append(\"homepage('\"+ movie_title +\"','\"+ home_page +\"')\")\n",
        " \n",
        "  for keyword in getattr(row, 'plot_keywords').split(\"|\"):\n",
        "    literals.append(\"keyword('\"+ movie_title +\"','\"+ clean_text(keyword) +\"')\")\n",
        "\n",
        "  id = getattr(row,\"id\")\n",
        "  literals.append(\"id('\"+ movie_title +\"','\"+ str(id) +\"')\")\n",
        "\n",
        "  language = getattr(row,\"language\")\n",
        "  literals.append(\"language('\"+ movie_title +\"','\"+ language +\"')\")\n",
        "\n",
        "  original_title = clean_text(getattr(row,\"original_title\"))\n",
        "  literals.append(\"original_title('\"+ movie_title +\"','\"+ original_title +\"')\")\n",
        "\n",
        "  overview = clean_text(getattr(row,\"overview\"))\n",
        "  literals.append(\"overview('\"+ movie_title +\"','\"+ overview +\"')\")\n",
        "\n",
        "  popularity = getattr(row,\"popularity\")\n",
        "  literals.append(\"popularity('\"+ movie_title +\"','\"+ str(popularity) +\"')\")\n",
        "  \n",
        "  for production_company in ast.literal_eval(getattr(row,\"production_companies\")):\n",
        "    literals.append(\"production_company('\"+ movie_title +\"','\"+ clean_text(str(production_company)) +\"')\")\n",
        "\n",
        "  for production_country in ast.literal_eval(getattr(row,\"production_countries\")):\n",
        "    literals.append(\"production_country('\"+ movie_title +\"','\"+ clean_text(str(production_country)) +\"')\")\n",
        "\n",
        "  release_date = getattr(row,\"release_date\")\n",
        "  literals.append(\"release_date('\"+ movie_title +\"','\"+ release_date +\"')\")\n",
        "\n",
        "  gross = getattr(row,\"gross\")\n",
        "  literals.append(\"gross('\"+ movie_title +\"','\"+ str(gross) +\"')\")\n",
        "\n",
        "  duration = getattr(row,\"duration\")\n",
        "  literals.append(\"duration('\"+ movie_title +\"','\"+ str(duration) +\"')\")\n",
        "\n",
        "  for spoken_language in ast.literal_eval(getattr(row,\"spoken_languages\")):\n",
        "    literals.append(\"spoken_language('\"+ movie_title +\"','\"+ clean_text(str(spoken_language)) +\"')\")\n",
        "\n",
        "  status = getattr(row,\"status\")\n",
        "  literals.append(\"status('\"+ movie_title +\"','\"+ status +\"')\")\n",
        "\n",
        "  tag_line = clean_text(getattr(row,\"tagline\"))\n",
        "  literals.append(\"tagline('\"+ movie_title +\"','\"+ tag_line +\"')\")\n",
        "\n",
        "  vote_average = getattr(row,\"vote_average\")\n",
        "  literals.append(\"vote_average('\"+ movie_title +\"','\"+ str(vote_average) +\"')\")\n",
        "\n",
        "  num_voted_users = getattr(row,\"num_voted_users\")\n",
        "  literals.append(\"num_voted_users('\"+ movie_title +\"','\"+ str(num_voted_users) +\"')\")\n",
        "\n",
        "  title_year = getattr(row,\"title_year\")\n",
        "  literals.append(\"title_year('\"+ movie_title +\"','\"+ str(title_year) +\"')\")\n",
        "\n",
        "  country = clean_text(getattr(row,\"country\"))\n",
        "  literals.append(\"country('\"+ movie_title +\"','\"+ country +\"')\")\n",
        "\n",
        "  director_name = clean_text(getattr(row,\"director_name\"))\n",
        "  literals.append(\"director_name('\"+ movie_title +\"','\"+ director_name +\"')\")\n",
        "\n",
        "  actor_1_name = clean_text(getattr(row,\"actor_1_name\"))\n",
        "  literals.append(\"actor_1_name('\"+ movie_title +\"','\"+ actor_1_name +\"')\")\n",
        "\n",
        "  actor_2_name = clean_text(getattr(row,\"actor_2_name\"))\n",
        "  literals.append(\"actor_2_name('\"+ movie_title +\"','\"+ actor_2_name +\"')\")\n",
        "\n",
        "  actor_3_name = clean_text(getattr(row,\"actor_3_name\"))\n",
        "  literals.append(\"actor_3_name('\"+ movie_title +\"','\"+ actor_3_name +\"')\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Η Prolog θέλει τα κατηγορήματά της με την σειρά \n",
        "literals.sort()\n",
        "for literal in literals:\n",
        "  prolog.assertz(literal)\n",
        "  #print (literal +'.')\n",
        "\n",
        "# #Επίσης μπορούμε να κάνουμε consult ένα έτοιμο αρχείο στον κόσμο όπως παρακάτω\n",
        "prolog.consult(path + \"db.pl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61SbKPrg4rUd",
        "outputId": "3099a739-2840-4ad0-8237-1aace0674df8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'Colored'\n"
          ]
        }
      ],
      "source": [
        "# 1. Κοινό θέμα (κάποιες λέξεις σχετικά με το genre κοινές)\n",
        "# 2. Αρκετά κοινό θέμα (κάποιες λιγότερες λέξεις σχετικά με το genre κοινές π.χ. 3)\n",
        "# 3. Σχετικά κοινό θέμα (λίγες λέξεις σχετικές με το genre κοινές π.χ. 1)\n",
        "# 4. Κοινός σκηνοθέτης\n",
        "# 5. Ακριβώς ίδια πλοκή (κάποιες λέξεις κλειδιά της πλοκής κοινές)\n",
        "# 6. Σχετικά ίδια πλοκή (κάποιες λιγότερες λέξεις κλειδιά κοινές)\n",
        "# 7. Ίδιους τους βασικούς ηθοποιούς (και τους 3)\n",
        "# 8. Αρκετά ίδιους βασικούς ηθοποιούς (ορισμένους βασικούς ηθοποιούς κοινούς π.χ. 2)\n",
        "# 9. Σχετικά ίδιους ηθοποιούς (π.χ. 1 από τους 3)\n",
        "# 10. Ίδια γλώσσα\n",
        "# 11. Είναι έγχρωμες ή ασπρόμαυρες\n",
        "# 12. Κοινό studio παραγωγής\n",
        "# 13. Κοινή χώρα παραγωγής \n",
        "# 14. Ίδια δεκαετία \n",
        "\n",
        "\n",
        "prolog.assertz('(directed_by(X,Y) :- findall(M,director_name(M,X),Y))')\n",
        "\n",
        "prolog.assertz('same_genres(X,Y) :- findall(M, (movie_title(M), findall(G1,genre(X,G1), L1), findall(G2,genre(M, G2), L2), X \\= M, intersection(L1,L2,L), length(L,N), N>4), Y)')\n",
        "prolog.assertz('similar_genres(X,Y) :- findall(M, (movie_title(M), findall(G1,genre(X,G1), L1), findall(G2,genre(M, G2), L2), X \\= M, intersection(L1,L2,L), length(L,N), N>3), Y)')\n",
        "prolog.assertz('relatively_similar_genres(X,Y) :- findall(M, (movie_title(M), findall(G1,genre(X,G1), L1), findall(G2,genre(M, G2), L2), X \\= M, intersection(L1,L2,L), length(L,N), N>1), Y)')\n",
        "\n",
        "prolog.assertz('same_director(X,Y) :- findall(M, (movie_title(M), X \\= M,director_name(X, D), director_name(M, D)), Y)')\n",
        "\n",
        "prolog.assertz('same_plot(X,Y) :- findall(M, (movie_title(M), findall(G1,keyword(X,G1), L1), findall(G2,keyword(M, G2), L2), X \\= M, intersection(L1,L2,L), length(L,N), N>4), Y)')\n",
        "prolog.assertz('similar_plot(X,Y) :- findall(M, (movie_title(M), findall(G1,keyword(X,G1), L1), findall(G2,keyword(M, G2), L2), X \\= M, intersection(L1,L2,L), length(L,N), N>2), Y)')\n",
        "\n",
        "\n",
        "prolog.assertz('same_actors(X,Y) :- findall(M, (movie_title(M), X \\= M, actor_1_name(X, A1), actor_2_name(X, A2), actor_3_name(X, A3), actor_1_name(M, B1), actor_2_name(M, B2), actor_3_name(M, B3), sort([A1,A2,A3], L1), sort([B1,B2,B3], L2), intersection(L1,L2,L), length(L,N), N=:=3), Y)')\n",
        "prolog.assertz('similar_actors(X,Y) :- findall(M, (movie_title(M), X \\= M, actor_1_name(X, A1), actor_2_name(X, A2), actor_3_name(X, A3), actor_1_name(M, B1), actor_2_name(M, B2), actor_3_name(M, B3), sort([A1,A2,A3], L1), sort([B1,B2,B3], L2), intersection(L1,L2,L), length(L,N), N>1), Y)')\n",
        "prolog.assertz('relatively_similar_actors(X,Y) :- findall(M, (movie_title(M), X \\= M, actor_1_name(X, A1), actor_2_name(X, A2), actor_3_name(X, A3), actor_1_name(M, B1), actor_2_name(M, B2), actor_3_name(M, B3), sort([A1,A2,A3], L1), sort([B1,B2,B3], L2), intersection(L1,L2,L), length(L,N), N>0), Y)')\n",
        "\n",
        "prolog.assertz('same_language(X,Y) :- findall(M, (movie_title(M), X \\= M , language(X ,L) , language(M, L)),Y)')\n",
        "\n",
        "# prolog.assertz('colored_movie(M) :- movie_title(M), findall(K, keyword(M, K), Y),(member(\"black and white scene\", Y) -> Output=\"Black and White\"; Output=\"Colored\")')\n",
        "\n",
        "prolog.assertz('colored_movie(M, C) :- movie_title(M), findall(K, keyword(M, K), Y), (member(\"black and white scene\", Y) -> C=\"Black and White\"; C=\"Colored\")')\n",
        "\n",
        "prolog.assertz('common_production_company(X,Y) :- findall(M, (movie_title(M), findall(G1,production_company(X,G1), L1), findall(G2,production_company(M, G2), L2), X \\= M, intersection(L1,L2,L), length(L,N), N>0), Y)')\n",
        "\n",
        "prolog.assertz('common_production_country(X,Y) :- findall(M, (movie_title(M), findall(G1,production_country(X,G1), L1), findall(G2,production_country(M, G2), L2), X \\= M, intersection(L1,L2,L), length(L,N), N>0), Y)')\n",
        "\n",
        "prolog.assertz('same_decade(X,Y) :- findall(M, (movie_title(M), movie_title(X), X \\= M, title_year(X,Y1), atom_number(Y1, N1), Decade1 is div(truncate(N1), 10), title_year(M, Y2), atom_number(Y2, N2), Decade2 is div(truncate(N2),10), Decade1 =:= Decade2), Y)')\n",
        "\n",
        "\n",
        "q = prolog.query(\"colored_movie('Avatar', C)\")\n",
        "for soln in q:\n",
        "    print(soln['C'])\n",
        "q.close()\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ibe9jBk24rUd"
      },
      "source": [
        "# **2ο Μέρος: Recommendation System με βάση μόνο τα χαρακτηριστικά των ταινιών.**\n",
        "\n",
        "Στο σημείο αυτό με βάση τους κανόνες που κατασκευάστηκαν στο Μέρος 1 θα κατασκευαστούν κατηγορήματα για την ομοιότητα ταινιών. Παρακάτω δίνεται ένα μικρό παράδειγμα ενός κανόνα και πώς αυτός θα μπορούσε να γραφτεί μέσω του Pyswip. Επίσης όπως αναφέρεται και σε σχόλιο παραπάνω θα μπορεί να γραφτεί και μια βάση δεδομένων με τους κανόνες και να γίνει απευθείας consult.\n",
        "\n",
        "Στο παρακάτω παράδειγμα το 5 και το 4 εκφράζουν την ομοιότητα των ταινιών π.χ. οι ταινίες που παράγονται μέσω του find_similar_5 είναι πιο όμοιες από αυτές που παράγονται μέσω του find_similar_4. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bh_jfhPC4rUd"
      },
      "outputs": [],
      "source": [
        "def simple_recommender(movie):\n",
        "    s = set()\n",
        "    q = prolog.query(\"find_sim_1('\" + movie +\"',M)\")\n",
        "    for soln in q:\n",
        "        m = soln['M'] \n",
        "        if m not in s:\n",
        "            s.add(soln['M'])\n",
        "    q.close()\n",
        "    answers = s\n",
        "    return answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ug_L_Qx-4rUd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['2 Fast 2 Furious',\n",
              " 'Timecop',\n",
              " 'Executive Decision',\n",
              " 'Snow White and the Huntsman',\n",
              " 'Hot Tub Time Machine']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(simple_recommender('Avatar'))[:5]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YjpTwOuO4rUd"
      },
      "source": [
        "# **3ο Μέρος: Recommendation System Με βάση τις προτιμήσεις-Αξιολογήσεις του χρήστη-Εκπαίδευση και Πρόβλεψη**\n",
        "\n",
        "\n",
        "Αρχικά μελετάμε τις αξιολογήσεις κάθε χρήστη για να καταλάβουμε την δομή και τις πληροφορίες κάθε αρχείου.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lL9P3GOd4rUe"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "rating_weights = {0: -1, 1: -0.5, 2:0, 3:0, 4:0.5, 5:1}\n",
        "score_weights = {i:i + 1 for i in range(1)} # ανάλογα με τα επίπεδα ομοιότητας που έχουν οριστεί στην simple_recommender\n",
        "\n",
        "def train_recommender(ratings, rating_weights, score_weights, number_of_movies = 10):\n",
        "    \"\"\"\n",
        "    Στην συνάρτηση αυτή μπορούμε να ορίζουμε ποιο υποσύνολο των αξιολογήσεων θα χρησιμοποιήσουμε για το train μαζί με τα βάρη ομοιότητας και σκορ\n",
        "    Σε συνδυασμό με τον αριθμό των ταινιών που θέλουμε να χρησιμοποιήσουμε σαν σύνολο δεδομένων π.χ. 10 από τις 100 ή 3 από τις 100 κ.ο.κ\n",
        "    Αν θέλουμε να χρησιμοποιήσουμε όλες τις ταινίες σαν training set τότε ορίζουμε το number_of_movies = - 1\n",
        "    \"\"\"\n",
        "\n",
        "    if number_of_movies > len(ratings):\n",
        "        number_of_movies = len(ratings)\n",
        "\n",
        "\n",
        "    if number_of_movies != -1:\n",
        "        indexes = random.sample(range(len(ratings)), number_of_movies)\n",
        "        ratings = ratings.iloc[indexes]\n",
        "\n",
        "    movie_score = {}\n",
        "    for row in tqdm(ratings.itertuples(index=True, name='Pandas')):\n",
        "        movie = clean_text(getattr(row, 'movie_title'))\n",
        "        rating = getattr(row, 'rating')\n",
        "\n",
        "        similar_movies = simple_recommender(movie)\n",
        "\n",
        "        for similar_movie in similar_movies:\n",
        "            if similar_movie not in movie_score:\n",
        "                movie_score[similar_movie] = rating_weights[int(rating)] * score_weights[0]\n",
        "            else:\n",
        "                movie_score[similar_movie] += rating_weights[int(rating)] * score_weights[0] # το weight θα το ορίσετε ανα επίπεδο ομοιότητας οι πολύ όμοιες ταινίες θα έχουν μεγαλύτερο βάρος\n",
        "    return movie_score\n",
        "\n",
        "\n",
        "# Αυτό είναι ένα παράδειγμα για το πως θα μπορούσε να υλοποιήθει η predict.\n",
        "# Έχουμε ορίσει ότι μια ταινία θα έπρεπε να είναι προτεινόμενη αν είχε σκορ > 0.\n",
        "def predict_example(ratings, movie_score):\n",
        "    real, pred = [], []\n",
        "    for i, row in enumerate(ratings.itertuples(index=True, name='Pandas')):\n",
        "        movie = clean_text(getattr(row, 'movie_title'))\n",
        "        rating = getattr(row, 'rating')\n",
        "\n",
        "        if movie in movie_score: #αν έχουμε σχηματίσει βαθμολογία για την ταινία αυτή\n",
        "            pred.append(int(movie_score[movie] > 0)) #heuristic για το αν μια ταινία είναι προτεινόμενη\n",
        "            real.append(int(rating > 3))# έτσι ορίζουμε ότι μια ταινία θα έπρεπε να είναι προτεινόμενη\n",
        "            #η συνθήκη αυτή δεν μπορεί να αλλάξει\n",
        "        else: #δεν μπορούμε να προτείνουμε κάτι για το όποιο δεν έχουμε σχηματίσει εικόνα\n",
        "            pred.append(0)\n",
        "            real.append(int(rating > 3))\n",
        "\n",
        "    return real, pred\n",
        "\n",
        "\n",
        "def get_metrics(real, pred):\n",
        "    metrics = {}\n",
        "    metrics[\"precision\"] = precision_score(real, pred)\n",
        "    metrics[\"recall\"] = recall_score(real, pred)\n",
        "    metrics[\"f1\"] = f1_score(real, pred)\n",
        "    return metrics"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IYusPpVKon2P"
      },
      "source": [
        "Η παραπάνω εκπαιδεύουν, τεστάρουν και μετρούν την απόδοσή του συστήματος στάσεων μας. Για την εκπαίδευση του συστήματος μπορούμε κάθε φορά να χρησιμοποιήσουμε ένα τυχαίο υποσύνολο του training set. Όμως είναι πιθανό το υποσύνολο των ταινιών αυτόν να επηρεάζει τα αποτελέσματα στο training set. Για παράδειγμα από 3 ταινίες στις 10 μπορούν για ένα πείραμα τα αποτελέσματα μας αν είναι ίδια και αυτό να μην οφείλεται στο γεγονός ότι ο ταξινομητής μας τα πηγαίνει καλά στις 3 ταινίες αλλά στο γεγονός ότι οι υπόλοιπες 7 είναι τέτοιες ταινίες που δεν μας βοηθούν καθόλου και αν είχαμε επιλέξει διαφορετικές 3 ταινίες να τα πηγαίναμε χάλια. Οπότε προτείνουμε να τρέξετε κάθε φορά έναν αριθμό πειραμάτων για κάθε υποσύνολο ταινιών π.χ. 10 πειράματα με 3 ταινίες, 10 πειράματα για 20 ταινίες κ.ο.κ. και να κρατήσετε σαν τελικό σκορ το μέσο όρο όλων των πειραμάτων. Έτσι τα αποτελέσματα των αγγλικών σας θα είναι πιο αντικειμενικά."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tnIDJLJX4rUe"
      },
      "outputs": [],
      "source": [
        "train_ratings = pd.read_csv(path + \"train_ratings.csv\")\n",
        "test_ratings = pd.read_csv(path + \"test_ratings.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IurBJXyA4rUe"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9c6a9cf63094c51b87ffbf626f7b8c3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d78aa4dda784d3ca46075c5e9559850",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44914334e82a44ae91ff7811a2b23648",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43252066027946b4bc0920da05e3c3d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65891fba37e34498863929859fc64e8e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e23d0de72a7e4b4fbf1a1fd17743a574",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19d3232ab6f4413e9a6ef16364255ca3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05cd48e22bd54625b3b844bd505e502f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e43ab9d298704ba8a2bb00b843319e6e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3670c893620b4e73a1c03726d265ec9f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "precision: 0.5185972917827617\n",
            "recall: 0.7\n",
            "f1: 0.5448269617513263\n"
          ]
        }
      ],
      "source": [
        "metrics = []\n",
        "for i in range (10):\n",
        "    movie_score = train_recommender(train_ratings, rating_weights, score_weights, 10)\n",
        "    real, pred = predict_example(test_ratings, movie_score)\n",
        "    metrics.append(get_metrics(real, pred))\n",
        "\n",
        "for metric in metrics[0].keys():\n",
        "    print (f\"{metric}: {np.mean([m[metric] for m in metrics])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CJGdc8wmndwd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69a732ffffec40af88a3eb5d84cd325a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d62414588beb4d18a5d6e38ad2acbe9c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90f8dfd2450644128ace0d945f6dd7ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m metrics \u001b[39m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m (\u001b[39m10\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     movie_score \u001b[39m=\u001b[39m train_recommender(train_ratings, rating_weights, score_weights, \u001b[39m30\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m     real, pred \u001b[39m=\u001b[39m predict_example(test_ratings, movie_score)\n\u001b[1;32m      5\u001b[0m     metrics\u001b[39m.\u001b[39mappend(get_metrics(real, pred))\n",
            "Cell \u001b[0;32mIn[10], line 29\u001b[0m, in \u001b[0;36mtrain_recommender\u001b[0;34m(ratings, rating_weights, score_weights, number_of_movies)\u001b[0m\n\u001b[1;32m     26\u001b[0m movie \u001b[39m=\u001b[39m clean_text(\u001b[39mgetattr\u001b[39m(row, \u001b[39m'\u001b[39m\u001b[39mmovie_title\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     27\u001b[0m rating \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(row, \u001b[39m'\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m similar_movies \u001b[39m=\u001b[39m simple_recommender(movie)\n\u001b[1;32m     31\u001b[0m \u001b[39mfor\u001b[39;00m similar_movie \u001b[39min\u001b[39;00m similar_movies:\n\u001b[1;32m     32\u001b[0m     \u001b[39mif\u001b[39;00m similar_movie \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m movie_score:\n",
            "Cell \u001b[0;32mIn[8], line 4\u001b[0m, in \u001b[0;36msimple_recommender\u001b[0;34m(movie)\u001b[0m\n\u001b[1;32m      2\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m      3\u001b[0m q \u001b[39m=\u001b[39m prolog\u001b[39m.\u001b[39mquery(\u001b[39m\"\u001b[39m\u001b[39mfind_sim_1(\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m movie \u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,M)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfor\u001b[39;00m soln \u001b[39min\u001b[39;00m q:\n\u001b[1;32m      5\u001b[0m     m \u001b[39m=\u001b[39m soln[\u001b[39m'\u001b[39m\u001b[39mM\u001b[39m\u001b[39m'\u001b[39m] \n\u001b[1;32m      6\u001b[0m     \u001b[39mif\u001b[39;00m m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m s:\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyswip/prolog.py:112\u001b[0m, in \u001b[0;36mProlog._QueryWrapper.__call__\u001b[0;34m(self, query, maxresult, catcherrors, normalize)\u001b[0m\n\u001b[1;32m    110\u001b[0m bindings \u001b[39m=\u001b[39m []\n\u001b[1;32m    111\u001b[0m swipl_list \u001b[39m=\u001b[39m PL_copy_term_ref(swipl_bindingList)\n\u001b[0;32m--> 112\u001b[0m t \u001b[39m=\u001b[39m getTerm(swipl_list)\n\u001b[1;32m    113\u001b[0m \u001b[39mif\u001b[39;00m normalize:\n\u001b[1;32m    114\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyswip/easy.py:436\u001b[0m, in \u001b[0;36mgetTerm\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    434\u001b[0m     res \u001b[39m=\u001b[39m _getterm_router[p](t)\n\u001b[1;32m    435\u001b[0m \u001b[39melif\u001b[39;00m PL_is_list(t):\n\u001b[0;32m--> 436\u001b[0m     res \u001b[39m=\u001b[39m getList(t)\n\u001b[1;32m    437\u001b[0m \u001b[39melif\u001b[39;00m p \u001b[39m==\u001b[39m PL_DICT:\n\u001b[1;32m    438\u001b[0m     res \u001b[39m=\u001b[39m getDict(t)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyswip/easy.py:483\u001b[0m, in \u001b[0;36mgetList\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    481\u001b[0m result \u001b[39m=\u001b[39m []\n\u001b[1;32m    482\u001b[0m \u001b[39mwhile\u001b[39;00m PL_get_list(t, head, t):\n\u001b[0;32m--> 483\u001b[0m     result\u001b[39m.\u001b[39mappend(getTerm(head))\n\u001b[1;32m    484\u001b[0m     head \u001b[39m=\u001b[39m PL_new_term_ref()\n\u001b[1;32m    486\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyswip/easy.py:440\u001b[0m, in \u001b[0;36mgetTerm\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    438\u001b[0m     res \u001b[39m=\u001b[39m getDict(t)\n\u001b[1;32m    439\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 440\u001b[0m     res \u001b[39m=\u001b[39m getFunctor(t)\n\u001b[1;32m    441\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyswip/easy.py:492\u001b[0m, in \u001b[0;36mgetFunctor\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetFunctor\u001b[39m(t):\n\u001b[1;32m    490\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return t as a functor\u001b[39;00m\n\u001b[1;32m    491\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 492\u001b[0m     \u001b[39mreturn\u001b[39;00m Functor\u001b[39m.\u001b[39;49mfromTerm(t)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyswip/easy.py:291\u001b[0m, in \u001b[0;36mFunctor.fromTerm\u001b[0;34m(cls, term)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[39mfor\u001b[39;00m i, a \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, arity \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[1;32m    290\u001b[0m     \u001b[39mif\u001b[39;00m PL_get_arg(a, term, a0 \u001b[39m+\u001b[39m i):\n\u001b[0;32m--> 291\u001b[0m         args\u001b[39m.\u001b[39mappend(getTerm(a0 \u001b[39m+\u001b[39;49m i))\n\u001b[1;32m    293\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(f\u001b[39m.\u001b[39mvalue, args\u001b[39m=\u001b[39margs, a0\u001b[39m=\u001b[39ma0)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyswip/easy.py:434\u001b[0m, in \u001b[0;36mgetTerm\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    432\u001b[0m p \u001b[39m=\u001b[39m PL_term_type(t)\n\u001b[1;32m    433\u001b[0m \u001b[39mif\u001b[39;00m p \u001b[39m<\u001b[39m PL_TERM:\n\u001b[0;32m--> 434\u001b[0m     res \u001b[39m=\u001b[39m _getterm_router[p](t)\n\u001b[1;32m    435\u001b[0m \u001b[39melif\u001b[39;00m PL_is_list(t):\n\u001b[1;32m    436\u001b[0m     res \u001b[39m=\u001b[39m getList(t)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyswip/easy.py:382\u001b[0m, in \u001b[0;36mgetAtom\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetAtom\u001b[39m(t):\n\u001b[1;32m    380\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"If t is an atom, return it , otherwise raise InvalidTypeError.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m     \u001b[39mreturn\u001b[39;00m Atom\u001b[39m.\u001b[39;49mfromTerm(t)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyswip/easy.py:81\u001b[0m, in \u001b[0;36mAtom.fromTerm\u001b[0;34m(cls, term)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[39mraise\u001b[39;00m ArgumentTypeError((\u001b[39mstr\u001b[39m(Term), \u001b[39mstr\u001b[39m(c_void_p)), \u001b[39mstr\u001b[39m(\u001b[39mtype\u001b[39m(term)))\n\u001b[1;32m     80\u001b[0m a \u001b[39m=\u001b[39m atom_t()\n\u001b[0;32m---> 81\u001b[0m \u001b[39mif\u001b[39;00m PL_get_atom(term, byref(a)):\n\u001b[1;32m     82\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(a\u001b[39m.\u001b[39mvalue, getAtomChars(term))\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "metrics = []\n",
        "for i in range (10):\n",
        "    movie_score = train_recommender(train_ratings, rating_weights, score_weights, 30)\n",
        "    real, pred = predict_example(test_ratings, movie_score)\n",
        "    metrics.append(get_metrics(real, pred))\n",
        "\n",
        "for metric in metrics[0].keys():\n",
        "    print (f\"{metric}: {np.mean([m[metric] for m in metrics])}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
